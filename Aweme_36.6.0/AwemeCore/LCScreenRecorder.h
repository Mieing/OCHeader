@class UIView, NSDate, CADisplayLink, AVAssetWriter, LCAudioBufferQueue, NSMutableDictionary, NSString, NSObject, LiveCore, AVAssetWriterInput, AVAssetWriterInputPixelBufferAdaptor;
@protocol OS_dispatch_queue, LCScreenRecorderProtocol, OS_dispatch_semaphore;

@interface LCScreenRecorder : NSObject {
    NSObject<OS_dispatch_queue> *_recorderQueue;
    BOOL _recording;
    struct AudioStreamBasicDescription { double mSampleRate; unsigned int mFormatID; unsigned int mFormatFlags; unsigned int mBytesPerPacket; unsigned int mFramesPerPacket; unsigned int mBytesPerFrame; unsigned int mChannelsPerFrame; unsigned int mBitsPerChannel; unsigned int mReserved; } _asbd;
    struct opaqueCMFormatDescription { } *_formatDesc;
    unsigned int _outPixelFormat;
}

@property (retain, nonatomic) NSMutableDictionary *bufferQueueList;
@property (retain, nonatomic) LCAudioBufferQueue *microphoneBufferQueue;
@property (retain, nonatomic) LCAudioBufferQueue *interactBufferQueue;
@property (nonatomic) BOOL hasUpdatedAudioFormat;
@property (nonatomic) BOOL hasUpdatedVideoFormat;
@property (nonatomic) struct { long long value; int timescale; unsigned int flags; long long epoch; } firstVideoPts;
@property (nonatomic) struct { long long value; int timescale; unsigned int flags; long long epoch; } firstAudioPts;
@property (nonatomic) BOOL enableVideo;
@property (nonatomic) BOOL enableAudio;
@property BOOL isApplicationActive;
@property (weak, nonatomic) LiveCore *engine;
@property (retain, nonatomic) AVAssetWriter *writer;
@property (retain, nonatomic) AVAssetWriterInput *videoInput;
@property (retain, nonatomic) AVAssetWriterInput *audioInput;
@property (retain, nonatomic) AVAssetWriterInputPixelBufferAdaptor *writerInputPixelBufferAdaptor;
@property (retain, nonatomic) CADisplayLink *displayLink;
@property (weak, nonatomic) UIView *targetView;
@property (retain, nonatomic) NSObject<OS_dispatch_semaphore> *frameRenderingSemaphore;
@property (nonatomic) double startRecordAbsoluteTime;
@property (nonatomic) double applicationWillResignActiveAbsoluteTime;
@property double inactiveAbsoluteTime;
@property (nonatomic) struct { long long value; int timescale; unsigned int flags; long long epoch; } startSampleTime;
@property (nonatomic) struct { long long value; int timescale; unsigned int flags; long long epoch; } lastSampleTime;
@property (nonatomic) double scale;
@property (nonatomic) struct CGColorSpace { } *rgbColorSpace;
@property (nonatomic) struct CGSize { double width; double height; } viewSize;
@property (nonatomic) struct CGRect { struct CGPoint { double x; double y; } origin; struct CGSize { double width; double height; } size; } drawRect;
@property (retain, nonatomic) NSDate *lastFrameDate;
@property (nonatomic) double lastFrameAbsoluteTime;
@property (nonatomic) double frameInterval;
@property (nonatomic) int audioInputStatus;
@property (weak, nonatomic) id<LCScreenRecorderProtocol> delegate;
@property (copy, nonatomic) NSString *outputPath;
@property (nonatomic) unsigned char frameRate;
@property (nonatomic) struct CGSize { double width; double height; } outputSize;
@property (nonatomic) long long bitrate;
@property (copy, nonatomic) id /* block */ bufferCallback;
@property (nonatomic) float elapse;
@property (nonatomic) BOOL canDrawInBackground;

- (void)applicationDidBecomeActiveNoti:(id)a0;
- (double)getFileSize:(id)a0;
- (void)setMasterLayer:(int)a0;
- (BOOL)prepareAudioInput;
- (void)processAudioBuffer:(struct opaqueCMSampleBuffer { } *)a0;
- (void)applicationWillResignActiveNoti:(id)a0;
- (BOOL)setupAssetWriter;
- (void)enqueueAudioBuffer:(void *)a0 numberOfFrames:(int)a1 numberOfchannels:(int)a2 track:(int)a3;
- (BOOL)startRecordingWithImageCallback:(id /* block */)a0;
- (void)destryDisplayLink;
- (void)__processAudioData;
- (void)__doMixAudioTo:(short *)a0 length:(short)a1;
- (struct { long long x0; int x1; unsigned int x2; long long x3; })__currentCMTime;
- (void)captureFrame:(id)a0;
- (BOOL)canVideoTransform;
- (struct CGAffineTransform { double x0; double x1; double x2; double x3; double x4; double x5; })videoTransformForDeviceOrientation;
- (BOOL)setupVideoInput;
- (id)initWithLiveCore:(id)a0;
- (BOOL)startScreenRecordingWithCaptureCallback:(id /* block */)a0;
- (void)__flushAudioBufferCache;
- (void)registerRenderWithView:(id)a0 uid:(id)a1;
- (void)updateLayoutForView:(id)a0 uid:(id)a1;
- (void)shouldUpdateLayout;
- (void)setSubview:(id)a0 enable:(BOOL)a1;
- (id)takeShotForView:(id)a0;
- (void)pushVideoBuffer:(struct opaqueCMSampleBuffer { } *)a0;
- (void).cxx_destruct;
- (void)cleanup;
- (id)audioSettings;
- (BOOL)isRecording;
- (void)setupDisplayLink;
- (void)stopRecording;
- (void)dealloc;
- (void)setContainerView:(id)a0;
- (BOOL)setAudioFormat:(struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; })a0;
- (void)cancelRecording;

@end
